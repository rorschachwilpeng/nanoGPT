{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 语料库数据"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:15.525331Z",
     "start_time": "2024-08-29T02:30:15.517704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir='./data/shakespeare_input.txt'\n",
    "with open(dir,'r',encoding='utf-8') as f:\n",
    "    text=f.read()\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:15.531433Z",
     "start_time": "2024-08-29T02:30:15.528624Z"
    }
   },
   "source": "print(len(text))#整个语料库大小",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:15.552082Z",
     "start_time": "2024-08-29T02:30:15.535284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#here are the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(f'vocabulary size:{vocab_size}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocabulary size:65\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 分词，训练集/验证集划分"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 分词\n",
    "这里用的是最简单的分词-字符级标记器（character-level tokenizer），创建两个字典用于存储映射关系。第一个字典存放字符->索引下标映射；第二个字典存放索引下标->字符映射。\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 拓展知识点\n",
    "在造分词器的时候，可以权衡codebook size（词汇表）和序列长度。\n",
    "可以拥有词汇量非常小的非常长的整数序列，也可以拥有词汇量非常大的短整数序列。\n",
    "？？？\n",
    "1. 词汇量非常小的非常长的整数序列：\n",
    "\n",
    "这指的是使用一个较小的词汇表，但允许序列（即文本中的单词或标记序列）有较长的长度。在这种情况下，每个词或标记可能由一个较大的整数来表示，因为词汇表中的项较少，所以可以使用较大的数值范围。\n",
    "这种方法可能适用于某些特定的应用场景，比如当文本数据具有高度的重复性，或者当模型需要处理非常长的文本序列时。\n",
    "2. 词汇量非常大的短整数序列：\n",
    "\n",
    "这指的是使用一个较大的词汇表，但限制序列的长度。在这种情况下，每个词或标记由一个较小的整数来表示，因为词汇表中的项较多，所以每个项的表示范围较小。\n",
    "这种方法可能更适用于处理多样化的文本数据，因为它能够捕捉到更多的词汇细节，但同时也需要考虑到模型的内存和计算效率，因为较大的词汇表可能会增加模型的复杂度。\n",
    "--------------\n",
    "个人理解\n",
    "\n",
    "如果词汇表很大的话，那么（极端情况下）每个词/字符/字节都会有对应的索引下标。这样会造成一句话的序列可能会很长，所以一般当文本很短的时候，我们可以用大词汇表，小序列长度的方式，增加对词汇细微差别的理解。例如：社交媒体文本通常包含大量的俚语、表情符号和个性化词汇。在这种情况下，可能需要一个较大的词汇表来捕捉这些多样化的表达方式，但由于内存和计算资源的限制，序列长度可能需要被限制。\n",
    "\n",
    "如果词汇表很小的话，序列长度很长的话。往往是用于一些重复率比较高的长文本。例如：生物信息学，\n",
    "在处理基因序列数据时，序列长度可以非常长，但使用的“词汇”（即核苷酸）只有四种（A、T、C、G）。这里，序列长度是关键，而词汇量非常小。\n",
    "\n",
    "--------------\n",
    "Q:如果在特定场景应用了不恰当的分词策略，会造成什么影响？\n",
    "\n",
    "Q:对话大模型在实际应用中会根据用户输入的字符长度来动态选择分词策略吗？"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:15.558056Z",
     "start_time": "2024-08-29T02:30:15.554130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###Tokenizers\n",
    "# create a mapping from characters to integers\n",
    "str2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2str = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [str2idx[c] for c in s]\n",
    "decode = lambda l: ''.join(idx2str[c] for c in l)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:15.563377Z",
     "start_time": "2024-08-29T02:30:15.560225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(encode('hii there'))\n",
    "print(decode(encode('hii there')))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在实践中，类似的分词策略例如：Google利用SentencePiece，即一种子词类型的标记器。该标记器没有对整个单词进行编码，也没有对单个字符进行编码。它是一个子字单元级别。\n",
    "\n",
    "OpenAI用了一个称为TickToken的库，它使用字节对编码标记器"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.621387Z",
     "start_time": "2024-08-29T02:30:15.582706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#将整个数据集进行编码\n",
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long)#这两个参数是什么意思？#这个函数在干嘛？\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/apple/Library/r-miniconda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/21/l9ygcw6d6w39m02vcn2t_j6r0000gn/T/ipykernel_1664/633919154.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/apple/Library/r-miniconda/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([ 0, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
      "        44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52,\n",
      "        63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,\n",
      "         1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39,\n",
      "        49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15,\n",
      "        47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50,\n",
      "        50,  1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1,\n",
      "        58, 53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51,\n",
      "        47, 57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43,\n",
      "        42,  8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1,\n",
      "        63, 53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56,\n",
      "        41, 47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51,\n",
      "        63,  1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0,\n",
      "        13, 50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,\n",
      "         1, 49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,\n",
      "         1, 46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39,\n",
      "        60, 43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,\n",
      "         1, 54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56,\n",
      "        42, 47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56,\n",
      "        43,  1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43,\n",
      "        58,  1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,\n",
      "         6,  1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45,\n",
      "        53, 53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56,\n",
      "        57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,\n",
      "         1, 39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47,\n",
      "        58, 47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41,\n",
      "        47, 39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59,\n",
      "        58, 46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53,\n",
      "        52,  1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57,\n",
      "        10,  1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47,\n",
      "        43, 50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54,\n",
      "        43, 56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,\n",
      "         1, 61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61,\n",
      "        43,  1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,\n",
      "         1, 56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52,\n",
      "        43, 50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52,\n",
      "        49,  1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,\n",
      "         1, 58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,\n",
      "         0, 39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1,\n",
      "        53, 40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43,\n",
      "        56, 63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52,\n",
      "        58, 53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56,\n",
      "        47, 57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41,\n",
      "        43, 11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1,\n",
      "        47, 57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1,\n",
      "        24, 43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47,\n",
      "        57,  1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1,\n",
      "        43, 56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43,\n",
      "        57, 10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52,\n",
      "        53, 61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,\n",
      "         1, 46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,\n",
      "         1, 52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,\n",
      "         1, 56, 43, 60, 43, 52, 45, 43,  8,  0])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分训练集/验证集"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.626074Z",
     "start_time": "2024-08-29T02:30:17.623140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]#训练集\n",
    "val_data = data[n:]#验证集"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.629982Z",
     "start_time": "2024-08-29T02:30:17.627207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854\n",
      "111540\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 数据加载器：批量数据块\n",
    "\n",
    "当我们训练Transformer时，我们不会将所有的语料一次性喂给模型。\n",
    "\n",
    "我们从训练集中随机抽取一个训练块进行训练，这些块的长度称为block_size"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.637570Z",
     "start_time": "2024-08-29T02:30:17.632034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#假设block_size为8，第一个block为\n",
    "block_size=8\n",
    "train_data[:block_size+1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 18, 47, 56, 57, 58,  1, 15, 47])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上面的代码中，之所以block_size要+1是因为：当你从训练集中抽取一块数据时，比如上述的例子中有9个字符，其实包含了8个示例。每个例子如下： \n",
    "\n",
    "为什么这里Karpathy提到输入的是Transformer的张量的时间维度"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.645197Z",
     "start_time": "2024-08-29T02:30:17.638664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = train_data[:block_size]#前block_size的元素\n",
    "y = train_data[1:block_size+1]#这里为什么是从1开始，为什么要到\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([0]) the target: 18\n",
      "when input is tensor([ 0, 18]) the target: 47\n",
      "when input is tensor([ 0, 18, 47]) the target: 56\n",
      "when input is tensor([ 0, 18, 47, 56]) the target: 57\n",
      "when input is tensor([ 0, 18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([ 0, 18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([ 0, 18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([ 0, 18, 47, 56, 57, 58,  1, 15]) the target: 47\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Batch size\n",
    "每次我们要将它们输入Transformer时，我们都会有许多批次的多个文本块，它们都堆叠在一个张量(tensor)中，这样做的原因是为了提高效率，以便利用GPU的并行计算能力来并行处理数据。这些块是完全独立处理的，彼此之间不通信。\n",
    "\n",
    "Every time we're going to feed them into a transformer, we're going to have many batches of multiple chunks of text that are all stacked up in a single tensor.\n",
    "\n",
    "所以单个tensor包含了多个batch（批次），每个批次包含了多个chunks"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.670542Z",
     "start_time": "2024-08-29T02:30:17.646623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for prediction?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split =='train' else val_data#输入训练数据/验证数据\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))#通过随机偏移量来选择不同的数据块\n",
    "    #生成偏移量的逻辑：在0-(len(data)-block_size)的范围内，随机生成batch_size个\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])#把这些随机抽取的序列进行拼接成batch\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "# print('input:')\n",
    "# print(xb.shape)\n",
    "# print(xb)\n",
    "# print('target:')\n",
    "# print(yb.shape)\n",
    "# print(yb)\n",
    "# \n",
    "# print('---------------')\n",
    "# \n",
    "# for b in range(batch_size):#batch dimension\n",
    "#     for t in range(block_size):#time dimension\n",
    "#         context=xb[b,:t+1]\n",
    "#         target=yb[b,t]\n",
    "#         print(f\"when input is {context.tolist()} the target: {target}\")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 最简单的基线：二元语法模型，损失，生成\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.675271Z",
     "start_time": "2024-08-29T02:30:17.672104Z"
    }
   },
   "cell_type": "code",
   "source": "vocab_size",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:17.770696Z",
     "start_time": "2024-08-29T02:30:17.676462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        #token embedding table -> 标记嵌入表,例如上述tensor中[[0,24,43,...],[...]..];\n",
    "        # 值为24的元素将在嵌入表中找到第24行，然后呢...?\n",
    "        #nn.Embedding -> 一个非常薄的包装器，基本上是一个形状为vocab_size*vocab_size的张量\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):#这是一个封装起来的强制函数\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #（B,T,C),在本例中,B(batch)批次为4，T(time)为8，C(chanel)为vocabSize即65\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:   \n",
    "            #利用负对数似然损失(negative log likelihood loss)衡量损失或预测质量，它也在PyTorch中以交叉熵的名称实现\n",
    "            #但是因为Pytorch对于cross_engropy的入参格式有要求，所以这里需要变换下维度\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)#将原先的4*8*65的三维数组扁平化至32*65\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits,loss\n",
    "        \n",
    "        #但是这里没有调用logits函数啊，怎么计算的呢\n",
    "    \n",
    "        #如果无视Batch的话，每个矩阵是一个8*65的矩阵。好像有点感觉，8代表时间维度（为什么叫做时间维度？），65代表\n",
    "        #总之得到的结果是每个senquece对于自己下一个词的预测分数？\n",
    "        #然后现在需要一个方法来衡量损失\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):#generate函数的主要目的是利用训练好的模型进行文本生成\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)#为什么这里会调用\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1,:]# becomes (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) #(B,C)\n",
    "            # sample form the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "            \n",
    "        \n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1,1),dtype=torch.long),max_new_tokens=100)[0].tolist()))\n",
    "\n",
    "#print(out.shape)\n",
    "#out[0].shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "上述评估结果为4.73，但是-In(1/65)结果并不在这个区间内"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ## 训练模型"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:18.497248Z",
     "start_time": "2024-08-29T02:30:17.772188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.366344Z",
     "start_time": "2024-08-29T02:30:18.500927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size=32\n",
    "for steps in range(10000):\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    ###经典的训练循环\n",
    "    # evalulate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    #将所有梯度归零->why?\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()#获取所有参数的梯度\n",
    "    optimizer.step()#使用这些梯度来更新我们的参数\n",
    "    #print(loss.item())\n",
    "print(loss.item())#该优化过程非常不稳定"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5532305240631104\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.412252Z",
     "start_time": "2024-08-29T02:30:36.367907Z"
    }
   },
   "cell_type": "code",
   "source": "print(decode(m.generate(idx = torch.zeros((1,1),dtype=torch.long),max_new_tokens=400)[0].tolist()))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henouratucenonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay.JUCle n prids, r loncave w hollular s O:\n",
      "HIs; ht anjx?\n",
      "\n",
      "DUThinqunt.\n",
      "\n",
      "LaZAnde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scar t tridesar, wnl'shenou\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 版本1:用for循环平均过去的上下文，聚合的最弱形式"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.422544Z",
     "start_time": "2024-08-29T02:30:36.413935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C=4,8,2 #batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.431710Z",
     "start_time": "2024-08-29T02:30:36.424074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#xbow: bag of words,词袋是人们在对事物进行平均时使用的术语\n",
    "xbow = torch.zeros(B,T,C)\n",
    "for b in range(B):#batch dimension（单次遍历：一句话）\n",
    "    for t in range(T):#time dimension(时间步，单次遍历：一个词)\n",
    "        xprev = x[b,:t+1]#(t,c) 为什么要加1->因为需要确保当前时间步的特征也被包括在内\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.438144Z",
     "start_time": "2024-08-29T02:30:36.433072Z"
    }
   },
   "cell_type": "code",
   "source": "x[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.443776Z",
     "start_time": "2024-08-29T02:30:36.439188Z"
    }
   },
   "cell_type": "code",
   "source": "xbow[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "xbow（词袋）结果是计算了每个当前时间步以及其历史的聚合特征，聚合方式是平均，虽然简单但是损失了大量空间特征"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 版本2:使用矩阵乘法"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 矩阵乘法的特点：C(3,2)=A(3,3)*B(3,2)\n",
    "2. 对于C矩阵中，第一行第一列元素为矩阵A的第一行和矩阵B第一列的点积\n",
    "3. 利用torch.tril()函数，可以只返回矩阵的下角部，上角部设置为0 -> 模拟masked attention\n",
    "4. 构造一个形状为time dim*time dim的数组->和步骤1中的矩阵A性质一样，这个矩阵包含了权重信息\n",
    "5. x（B*T,C）->步骤1中的矩阵B\n",
    "6. xbow2 = wei @ x\n",
    "\n",
    "    做矩阵乘法：(T,T) @ (B,T,C)\n",
    "   \n",
    "    两个矩阵形状不同，PyTorch会自动补全第一个矩阵，将其形状变换为(B,T,C)\n",
    "\n",
    "    得到的矩阵形状为（B,T,C）\n",
    "\n",
    "\n",
    "上述步骤通过批量矩阵乘法(batch matrix multiply)，实现了加权聚合"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.462987Z",
     "start_time": "2024-08-29T02:30:36.445063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)#keepdim:是否平均\n",
    "xbow2 = wei @ x # (T,T) @ (B,T,C)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.472799Z",
     "start_time": "2024-08-29T02:30:36.464265Z"
    }
   },
   "cell_type": "code",
   "source": "torch.allclose(xbow2,xbow)#证明两个构造矩阵是相似的",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.479754Z",
     "start_time": "2024-08-29T02:30:36.474358Z"
    }
   },
   "cell_type": "code",
   "source": "xbow[0], xbow2[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 版本3:添加Softmax"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 权重初始为“0”而不是“1”的原因：增加亲和力，亲和力可以理解成注意力权重\n",
    "2. 掩码因果关系：通过将当前时间步之后的元素'-inf'，表示我们不会从这些token中聚合任何东西\n",
    "3. 为什么F.softmax()函数中的dim参数为-1 ---->每一列的权重被归一化,这通常用于处理列向量，例如在某些注意力机制中，每列代表一个时间步的权重\n",
    "4. 若dim设置为1->每一行的权重被归一化\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.489643Z",
     "start_time": "2024-08-29T02:30:36.480824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))#掩码因果关系\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow,xbow3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.495600Z",
     "start_time": "2024-08-29T02:30:36.490941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wei = F.softmax(wei, dim=1)\n",
    "wei[0][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2797)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 自注意力"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "自注意力解决的问题：\n",
    "对于一个时间步元素，希望其他元素以基于数据依赖的方式涌向自己\n",
    "\n",
    "**自注意力机制：**\n",
    "\n",
    "每个节点或每个位置的每个标记都会发出两个向量：Query（查询向量）和Key（键）。查询向量意义：我在寻找什么；键向量意义：我包含什么。\n",
    "\n",
    "在序列中获得这些标记之间的亲和力的方式基本上是在键和查询之间进行点积，所以我的查询与所有其他标记的所有键进行点积，这个点积现在变成了重量(weight)。如果某两个标记之间是一致的，它们将以非常高的量相互作用。因此，我将更多地关注这个标记，而不是序列中的其他标记。\n",
    "\n",
    "感性理解q.k,v：\n",
    "\n",
    "每个x可以理解成当前标记的私人信息。query是当前标记寻找的信息，key是当前标记/节点包含的信息。如果其他标记对当前标记感兴趣的话，当前标记提供的信息是value。这个比喻类似于电影分类的比喻；观众有感兴趣的电影类型（动作片，query），电影院中有不同类型的电影（爱情片，惊悚片，动作片...key），具体的电影有（北京遇上西雅图，闪灵，霍元甲...value）。\n",
    "\n",
    "\n",
    "整个机制的数学表达式：\n",
    "假设输入序列长度为 \\( T \\)，特征维度为 \\( D \\)。\n",
    "\n",
    "查询 \\( Q \\)、键 \\( K \\) 和值 \\( V \\) 的线性变换：\n",
    "$$\n",
    "Q = W^Q \\cdot x + b^Q\n",
    "$$\n",
    "输入 \\( x \\) 经过查询权重矩阵 \\( W^Q \\) 和偏置 \\( b^Q \\)。\n",
    "\n",
    "$$\n",
    "K = W^K \\cdot x + b^K\n",
    "$$\n",
    "输入 \\( x \\) 经过键权重矩阵 \\( W^K \\) 和偏置 \\( b^K \\)。\n",
    "\n",
    "$$\n",
    "V = W^V \\cdot x + b^V\n",
    "$$\n",
    "输入 \\( x \\) 经过值权重矩阵 \\( W^V \\) 和偏置 \\( b^V \\)。\n",
    "\n",
    "计算注意力得分（缩放点积）：\n",
    "$$\n",
    "\\text{Attention}_\\text{Scores} = \\frac{Q \\cdot K^T}{\\sqrt{D_k}}\n",
    "$$\n",
    "\n",
    "应用softmax函数归一化：\n",
    "$$\n",
    "\\text{Attention}_\\text{Weights} = \\text{softmax}(\\text{Attention}_\\text{Scores})\n",
    "$$\n",
    "\n",
    "计算加权值：\n",
    "$$\n",
    "\\text{Weighted}_\\text{Values} = V \\odot \\text{Attention}_\\text{Weights}\n",
    "$$\n",
    "\n",
    "求和得到最终的注意力输出：\n",
    "$$\n",
    "\\text{Attention}_\\text{Output} = \\sum_{t=1}^{T} \\text{Weighted}_\\text{Values}_t\n",
    "$$\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.515125Z",
     "start_time": "2024-08-29T02:30:36.496769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32#batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single head self-attention\n",
    "head_size=16#有什么用\n",
    "key=nn.Linear(C,head_size, bias=False)\n",
    "query=nn.Linear(C,head_size, bias=False)\n",
    "value=nn.Linear(C,head_size, bias=False)\n",
    "\n",
    "k=key(x)\n",
    "q=query(x)\n",
    "wei = q @ k.transpose(-2, -1) #(B,T,16) @ (B,16,T) ----> (B,T,T)\n",
    "#为什么要转置key矩阵-\n",
    "# >为了确保执行点积时，query和key向量能在维度上对齐\n",
    "# ->输出维度：\n",
    "# 转置键矩阵会影响点积操作的输出维度。例如，如果查询矩阵 Q 的形状是 (B, T_q, D_k)，键矩阵 K 的形状是 (B, T_k, D_k)，其中 B 是批次大小，T_q 和 T_k 分别是查询序列和键序列的长度，D_k 是键的维度。转置 K 后，K 的形状变为 (B, D_k, T_k)。这样，Q 和 K^T 进行矩阵乘法得到的注意力得分矩阵 Attention_Scores 形状将是 (B, T_q, T_k)，表示每个查询时间步对于每个键时间步的得分。\n",
    "\n",
    "\n",
    "###内部机制\n",
    "tril = torch.tril(torch.ones(T,T))#构造上角部掩码矩阵\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))#因果掩码(Encoder只需要注释掉这行，即允许当前时间步的token同时看到上下文)\n",
    "wei = F.softmax(wei, dim=-1)#通过softmax概率函数，将权重归一化，使得每个列向量权重相加为1\n",
    "###\n",
    "\n",
    "v = value(x)#v是我们聚合的元素，或者我们聚合的向量，而不是原始的x；聚合成(B, T, head_size)\n",
    "out = wei @ v\n",
    "out.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.521104Z",
     "start_time": "2024-08-29T02:30:36.516630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_test = wei @ x\n",
    "out_test.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.（注意力是一种通信机制。可以将其视为有向图中的节点相互观察，并根据指向它们的所有节点以数据依赖的权重尽心加权求和来聚合信息。）\n",
    "\n",
    "\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens（注意力不包含空间信息，所以我们需要加入位置编码）\n",
    "\n",
    "\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other（每个batch的数据都是独立处理的，不与其他batch进行通信。）\n",
    "\n",
    "\n",
    "- In an \"encoder\" attention block just delete the single line that does making with *trill*, allowing all tokens to communicate. Here is called a \"decoder\" attention block because it has triangular masking, and is usually in autoregressive setting（编码器就是删除掉因果掩码的decoder，即允许当前时间步的token和上下文所有的token之间进行通信）\n",
    "\n",
    "\n",
    "- \"self-attention\" just means that the keys and values are produced from the same sources as queries. In \"cross-attention\", the queries get produced from x, but the keys and values come from some other, external sources（.e.g. an encoder module）（自注意力机制意味着key, value, query都来自于x；而交叉注意力机制中，x只生成query；而key和value都来自于外部，例如encoder） "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### “缩放”自注意力。为什么除以sqrt(head_size)构建Transformer\n",
    "\n",
    "当权重的值过于大或者过于小的话，Softmax函数的生成值会开始锐化，甚至收敛到One-Hot Vectors。见下面例子"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.527232Z",
     "start_time": "2024-08-29T02:30:36.522491Z"
    }
   },
   "cell_type": "code",
   "source": "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.533481Z",
     "start_time": "2024-08-29T02:30:36.528510Z"
    }
   },
   "cell_type": "code",
   "source": "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-Head Attention"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "前馈层的实现比较简单，只是将单注意力变成多头"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.536587Z",
     "start_time": "2024-08-29T02:30:36.534825Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer块的前馈层"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 什么是前馈层？\n",
    "在Transformer架构中，前馈层（Feed-Forward Neural Network，FFN）是位于多头自注意力机制之后的一组线性变换，用于进一步处理数据。Transformer模型的每个编码器（Encoder）和解码器（Decoder）层中都包含前馈层。\n",
    "\n",
    "前馈层的基本结构：\n",
    "第一层线性变换：输入数据首先通过一个线性层，通常是一个全连接的神经网络层，将数据从原始维度映射到一个新的维度。\n",
    "\n",
    "非线性激活函数：在第一层线性变换之后，通常会应用一个非线性激活函数，如ReLU（Rectified Linear Unit）。\n",
    "\n",
    "第二层线性变换：然后，数据通过另一个线性层，将数据从激活函数的输出维度映射回原始维度。\n",
    "\n",
    "前馈层的作用：\n",
    "在利用注意力机制收集了数据后，前馈层允许每个注意力头思考收集到的信息（抽象捏）\n",
    "\n",
    "（没懂）"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 残差连接\n",
    "\n",
    "也叫做skip connections（跳过连接），有时也称为残差连接（residual connections）\n",
    "\n",
    "残差连接有什么用？为什么能优化模型？梯度为什么\n",
    "将输入直接添加到网络的后一个后续层的输出上，从而允许网络学习残差函数。\n",
    "\n",
    "残差连接的关键特点：\n",
    "\n",
    "直接连接：在残差连接中，输入通过一个恒等映射（通常是1x1的卷积或简单的相加操作）直接连接到网络的深层。\n",
    "\n",
    "\n",
    "简化学习：残差连接简化了网络的学习任务，因为网络可以学习输入和输出之间的残差（即差异），而不仅仅是输出。\n",
    "\n",
    "\n",
    "避免梯度消失：在深层网络中，梯度可能会随着层的增加而逐渐消失。残差连接通过直接连接帮助梯度流动，从而缓解了这个问题。\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:30:36.539690Z",
     "start_time": "2024-08-29T02:30:36.537710Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dropout\n",
    "\n",
    "一种正则化技术，可以在神经网络前向-后项传递时随机关闭掉一些神经元（把它们的权重调整为0），主要用来防止过拟合\n",
    "\n",
    "dropout添加位置：\n",
    "1. 前馈层末尾\n",
    "\n",
    "2. 多头扩展末尾\n",
    "\n",
    "3. 计算完亲和力和softmax之后（注意力得分）"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#1:42:54\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
